modeloCaret<-train(Species~.,data=train,method="nb",trControl = ct)
View(datos)
knitr::opts_chunk$set(echo = TRUE)
#Ingebor Rubio/Desktop/Trabajos/Quinto Semestre/Mineria/HDT4RegresionLineal
#C:/Users/Andree/Documents/GitHub/HDT3-ArbolesDeDecision
#"C:/Users/andre/OneDrive/Documentos/HDT5Bayes"
#"C:/Users/andre/OneDrive/Documentos/HDT4RegresionLineal"
knitr::opts_knit$set(root.dir="C:/Users/andre/OneDrive/Documentos/HDT5Bayes")
model <- rpart(clasificacion~., train,method = "class")
library(rpart)
model <- rpart(clasificacion~., train,method = "class")
library(rpart)
model <- rpart(datosCasa$clasificacion~., train,method = "class")
library(rpart)
model <- rpart(datosCasas$clasificacion~., train,method = "class")
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
model <- rpart(clasificacion~., train,method = "class")
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
View(test)
model <- rpart(clasificacion~., train,method = "class")
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
View(train)
model <- rpart(clasificacion~., train,method = "class")
View(test)
library(e1071)
library(caret)
library(magrittr)
library(dplyr)
library(plyr)
library(dplyr)
library(cluster)
library(e1071)
library(mclust)
library(fpc)
library(NbClust)
library(factoextra)
library(tidyverse)
library(e1071)
library(caret)
library(magrittr)
library(dplyr)
library(plyr)
library(dplyr)
library(cluster)
library(e1071)
library(mclust)
library(fpc)
library(NbClust)
library(factoextra)
library(tidyverse)
library(e1071)
library(caret)
library(magrittr)
library(dplyr)
library(plyr)
library(dplyr)
library(cluster)
library(e1071)
library(mclust)
library(fpc)
library(NbClust)
library(factoextra)
#library(tidyverse)
library(readr)
library(ppclust)
library(randomForest)
library(ggplot2)
library(broom)
library(ggpubr)
library(corrplot)
library(mctest)
library(caret)
library(Amelia)
library(caretEnsemble)
library(psych)
library(mice)
library(GGally)
library(rpart)
library(e1071)
datos <- read.csv("train.csv")
datosCasas <- datos[,-c(1,7)]
#for(i in 1:ncol(datosCasas)){
#  datosCasas[is.na(datosCasas[,i]), i] <- mean(datosCasas[,i], na.rm = TRUE)
#}
#Mode <- function (x, na.rm) {
#    xtab <- table(x)
#    xmode <- names(which(xtab == max(xtab)))
#    if (length(xmode) > 1) xmode <- ">1 mode"
#    return(xmode)
#}
#for (var in 1:ncol(datosCasas)) {
#    if (class(datosCasas[,var])=="numeric") {
#        datosCasas[is.na(datosCasas[,var]),var] <- mean(datosCasas[,var], na.rm = TRUE)
#    } else if (class(datosCasas[,var]) %in% c("character", "factor")) {
#        datosCasas[is.na(datosCasas[,var]),var] <- Mode(datosCasas[,var], na.rm = TRUE)
#    }
#}
getmode <- function(v){
v=v[nchar(as.character(v))>0]
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
for (cols in colnames(datosCasas)) {
if (cols %in% names(datosCasas[,sapply(datosCasas, is.numeric)])) {
datosCasas<-datosCasas%>%mutate(!!cols := replace(!!rlang::sym(cols), is.na(!!rlang::sym(cols)), mean(!!rlang::sym(cols), na.rm=TRUE)))
}
else {
datosCasas<-datosCasas%>%mutate(!!cols := replace(!!rlang::sym(cols), !!rlang::sym(cols)=="", getmode(!!rlang::sym(cols))))
}
}
datosCasas <- datosCasas[,-29]
datosCasas <- datosCasas[,-29]
datosCasas <- datosCasas[,-29]
datosCasas <- datosCasas[,-29]
datosCasas <- datosCasas[,-30]
datosCasas <- datosCasas[,-24]
#View(datosCasas)
porciento <- 70/100
datosCasas$clasificacion <- ifelse(datosCasas$SalePrice <= 251000, "Economicas", ifelse(datosCasas$SalePrice <= 538000, "Intermedias", ifelse(datosCasas$SalePrice <= 755000, "Caras")))
datosCasas$y <- factor(datosCasas$clasificacion)
set.seed(123)
trainRowsNumber<-sample(nrow(datosCasas),porciento*nrow(datosCasas))
train<-datosCasas[trainRowsNumber,]
test<-datosCasas[-trainRowsNumber,]
modelo<-naiveBayes(train$y~., data=train)
modelo
View(train)
View(test)
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
model <- rpart(clasificacion~., train,method = "class")
plot(model);text(model)
prp(model)
rpart.plot(model)
head(test)
pred <- predict(model, newdata = test[1:81])
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
model <- rpart(clasificacion~., train,method = "class")
plot(model);text(model)
prp(model)
rpart.plot(model)
head(test)
pred <- predict(model, newdata = test[1:50])
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
model <- rpart(clasificacion~., train,method = "class")
plot(model);text(model)
prp(model)
rpart.plot(model)
pred <- predict(model, newdata = test[1:50])
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
model <- rpart(clasificacion~., train,method = "class")
plot(model);text(model)
prp(model)
rpart.plot(model)
pred <- predict(model, newdata = test[1:50])
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
model <- rpart(clasificacion~., train,method = "class")
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
model <- rpart(clasificacion~., train,method = "class")
plot(model);text(model)
prp(model)
rpart.plot(model)
pred <- predict(model, newdata = test[1:49])
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
model <- rpart(clasificacion~., train,method = "class")
plot(model);text(model)
prp(model)
rpart.plot(model)
pred <- predict(model, newdata = test[1:81])
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
model <- rpart(clasificacion~., train,method = "class")
plot(model);text(model)
prp(model)
rpart.plot(model)
pred <- predict(model, newdata = test[1:70])
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
model <- rpart(clasificacion~., train,method = "class")
plot(model);text(model)
prp(model)
rpart.plot(model)
pred <- predict(model, newdata = test[1:80])
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
model <- rpart(clasificacion~., train,method = "class")
plot(model);text(model)
prp(model)
rpart.plot(model)
pred <- predict(model, newdata = test[1:79])
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
model <- rpart(clasificacion~., train,method = "class")
plot(model);text(model)
prp(model)
rpart.plot(model)
pred <- predict(model, newdata = test[1:75])
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
model <- rpart(clasificacion~., train,method = "class")
plot(model);text(model)
prp(model)
rpart.plot(model)
pred <- predict(model, newdata = test[1:76])
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
model <- rpart(clasificacion~., train,method = "class")
plot(model);text(model)
prp(model)
rpart.plot(model)
pred <- predict(model, newdata = test[1:75])
knitr::opts_chunk$set(echo = TRUE)
#"C:/Users/andre/OneDrive/Documentos/HT1.Analisis-Exploratorio"
#Ingebor Rubio/Desktop/Trabajos/Quinto Semestre/Mineria/HDT3-ArbolesDeDecision
#C:/Users/Andree/Documents/GitHub/HDT3-ArbolesDeDecision
knitr::opts_knit$set(root.dir="C:/Users/andre/OneDrive/Documentos/HT1.Analisis-Exploratorio")
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el n?mero de clusters ?ptimo
library(factoextra) #Para hacer gr?ficos bonitos de clustering
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
library(rpart)
library(ISLR)
library(MASS)
library(dplyr)
# variable respuesta
porciento <- 70/100
datosCasas$clasificacion <- ifelse(datosCasas$SalePrice <= 251000, "Economicas", ifelse(datosCasas$SalePrice <= 538000, "Intermedias", ifelse(datosCasas$SalePrice <= 755000, "Caras")))
set.seed(123)
trainRowsNumber<-sample(1:nrow(datosCasas),porciento*nrow(datosCasas))
train<-datosCasas[trainRowsNumber,]
test<-datosCasas[-trainRowsNumber,]
arbolModelo<-rpart(SalePrice~.,datosCasas,method = "anova")
rpart.plot(arbolModelo)
datosCasas <- read.csv("train.csv")
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
model <- rpart(clasificacion~., train,method = "class")
plot(model);text(model)
prp(model)
rpart.plot(model)
pred <- predict(model, newdata = test[1:81])
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
model <- rpart(clasificacion~., train,method = "class")
plot(model);text(model)
prp(model)
rpart.plot(model)
prediccion <- predict(model, newdata = test[1:81])
View(train)
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
model <- rpart(clasificacion~., train,method = "class")
plot(model);text(model)
prp(model)
rpart.plot(model)
pred <- predict(model, newdata = test[1:80])
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
model <- rpart(clasificacion~., train,method = "class")
plot(model);text(model)
prp(model)
rpart.plot(model)
pred <- predict(model, newdata = test[1:50])
library(e1071)
library(caret)
library(magrittr)
library(dplyr)
library(plyr)
library(dplyr)
library(cluster)
library(e1071)
library(mclust)
library(fpc)
library(NbClust)
library(factoextra)
#library(tidyverse)
library(readr)
library(ppclust)
library(randomForest)
library(ggplot2)
library(broom)
library(ggpubr)
library(corrplot)
library(mctest)
library(caret)
library(Amelia)
library(caretEnsemble)
library(psych)
library(mice)
library(GGally)
library(rpart)
library(e1071)
datos <- read.csv("train.csv")
datosCasas <- datos[,-c(1,7)]
#for(i in 1:ncol(datosCasas)){
#  datosCasas[is.na(datosCasas[,i]), i] <- mean(datosCasas[,i], na.rm = TRUE)
#}
#Mode <- function (x, na.rm) {
#    xtab <- table(x)
#    xmode <- names(which(xtab == max(xtab)))
#    if (length(xmode) > 1) xmode <- ">1 mode"
#    return(xmode)
#}
#for (var in 1:ncol(datosCasas)) {
#    if (class(datosCasas[,var])=="numeric") {
#        datosCasas[is.na(datosCasas[,var]),var] <- mean(datosCasas[,var], na.rm = TRUE)
#    } else if (class(datosCasas[,var]) %in% c("character", "factor")) {
#        datosCasas[is.na(datosCasas[,var]),var] <- Mode(datosCasas[,var], na.rm = TRUE)
#    }
#}
getmode <- function(v){
v=v[nchar(as.character(v))>0]
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
for (cols in colnames(datosCasas)) {
if (cols %in% names(datosCasas[,sapply(datosCasas, is.numeric)])) {
datosCasas<-datosCasas%>%mutate(!!cols := replace(!!rlang::sym(cols), is.na(!!rlang::sym(cols)), mean(!!rlang::sym(cols), na.rm=TRUE)))
}
else {
datosCasas<-datosCasas%>%mutate(!!cols := replace(!!rlang::sym(cols), !!rlang::sym(cols)=="", getmode(!!rlang::sym(cols))))
}
}
datosCasas <- datosCasas[,-29]
datosCasas <- datosCasas[,-29]
datosCasas <- datosCasas[,-29]
datosCasas <- datosCasas[,-29]
datosCasas <- datosCasas[,-30]
datosCasas <- datosCasas[,-24]
#View(datosCasas)
porciento <- 70/100
datosCasas$clasificacion <- ifelse(datosCasas$SalePrice <= 251000, "Economicas", ifelse(datosCasas$SalePrice <= 538000, "Intermedias", ifelse(datosCasas$SalePrice <= 755000, "Caras")))
datosCasas$y <- factor(datosCasas$clasificacion)
set.seed(123)
trainRowsNumber<-sample(nrow(datosCasas),porciento*nrow(datosCasas))
train<-datosCasas[trainRowsNumber,]
test<-datosCasas[-trainRowsNumber,]
modelo<-naiveBayes(train$y~., data=train)
modelo
View(train)
View(train)
library(e1071)
library(caret)
library(magrittr)
library(dplyr)
library(plyr)
library(dplyr)
library(cluster)
library(e1071)
library(mclust)
library(fpc)
library(NbClust)
library(factoextra)
#library(tidyverse)
library(readr)
library(ppclust)
library(randomForest)
library(ggplot2)
library(broom)
library(ggpubr)
library(corrplot)
library(mctest)
library(caret)
library(Amelia)
library(caretEnsemble)
library(psych)
library(mice)
library(GGally)
library(rpart)
library(e1071)
datos <- read.csv("train.csv")
datosCasas <- datos[,-c(1,7)]
#for(i in 1:ncol(datosCasas)){
#  datosCasas[is.na(datosCasas[,i]), i] <- mean(datosCasas[,i], na.rm = TRUE)
#}
#Mode <- function (x, na.rm) {
#    xtab <- table(x)
#    xmode <- names(which(xtab == max(xtab)))
#    if (length(xmode) > 1) xmode <- ">1 mode"
#    return(xmode)
#}
#for (var in 1:ncol(datosCasas)) {
#    if (class(datosCasas[,var])=="numeric") {
#        datosCasas[is.na(datosCasas[,var]),var] <- mean(datosCasas[,var], na.rm = TRUE)
#    } else if (class(datosCasas[,var]) %in% c("character", "factor")) {
#        datosCasas[is.na(datosCasas[,var]),var] <- Mode(datosCasas[,var], na.rm = TRUE)
#    }
#}
getmode <- function(v){
v=v[nchar(as.character(v))>0]
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
for (cols in colnames(datosCasas)) {
if (cols %in% names(datosCasas[,sapply(datosCasas, is.numeric)])) {
datosCasas<-datosCasas%>%mutate(!!cols := replace(!!rlang::sym(cols), is.na(!!rlang::sym(cols)), mean(!!rlang::sym(cols), na.rm=TRUE)))
}
else {
datosCasas<-datosCasas%>%mutate(!!cols := replace(!!rlang::sym(cols), !!rlang::sym(cols)=="", getmode(!!rlang::sym(cols))))
}
}
datosCasas <- datosCasas[,-29]
datosCasas <- datosCasas[,-29]
datosCasas <- datosCasas[,-29]
datosCasas <- datosCasas[,-29]
datosCasas <- datosCasas[,-30]
datosCasas <- datosCasas[,-24]
datosCasas <- datosCasas[,-50]
#View(datosCasas)
porciento <- 70/100
datosCasas$clasificacion <- ifelse(datosCasas$SalePrice <= 251000, "Economicas", ifelse(datosCasas$SalePrice <= 538000, "Intermedias", ifelse(datosCasas$SalePrice <= 755000, "Caras")))
datosCasas$y <- factor(datosCasas$clasificacion)
set.seed(123)
trainRowsNumber<-sample(nrow(datosCasas),porciento*nrow(datosCasas))
train<-datosCasas[trainRowsNumber,]
test<-datosCasas[-trainRowsNumber,]
modelo<-naiveBayes(train$y~., data=train)
modelo
View(train)
library(e1071)
library(caret)
na.action(train)
train[is.na(train)] <- 0
ct<-trainControl(method = "cv",train[,1:49],number=10, verboseIter=T)
modeloCaret<-train(y~.,data=train,method="nb",trControl = ct)
library(e1071)
library(caret)
#na.action(train)
#train[is.na(train)] <- 0
#ct<-trainControl(method = "cv",train[,1:49],number=10, verboseIter=T)
#modeloCaret<-train(y~.,data=train,method="nb",trControl = ct)
#prediccionCaret<-predict(modeloCaret,newdata = test[,1:49])
#caret::confusionMatrix(prediccionCaret,test$y)
#Prueba 2
ct <- trainControl(method = "cv", verboseIter = T)
modeloCaret <- train(train$clasificacion~.,data = train, method = "nb", trControl = ct)
